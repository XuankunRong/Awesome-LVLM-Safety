# ðŸ¤—ðŸ¤—ðŸ¤— Awesome LVLM Safety [![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![License](https://img.shields.io/badge/License-CC_BY--NC_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc/4.0/) [![GitHub stars](https://img.shields.io/github/stars/XuankunRong/Awesome-LVLM-Safety?style=social)](https://github.com/XuankunRong/Awesome-LVLM-Safety)

> Curated list of Large Vision-Language Model Safety resources, aligned with our survey:  
> **A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations**

## ðŸ“œ Table of Contents

<details>
<summary>Click to expand</summary>

- [Attacks](#attacks)
- [Defenses](#defenses)
- [Evaluations](#evaluations)

</details>

<h2> <img src="assets/attack.png" alt="Icon" width="20" style="vertical-align:middle"/> Attacks </h2>

<h2> <img src="assets/defense.png" alt="Icon" width="18" style="vertical-align:middle"/> Defenses </h2>

<h2> <img src="assets/evaluation.png" alt="Icon" width="27" style="vertical-align:middle"/> Evaluations </h2>




